\documentclass[11pt,dvipsnames,usenames,aspectratio=169]{beamer}  % Add handout to options to disable overlays

% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{%
  \usetheme{CambridgeUS}    % or try default, Darmstadt, Warsaw, ...
  \usecolortheme{whale}     % or try albatross, beaver, crane, ...
  \usefonttheme{serif}          % or try default, structurebold, ...
  % \usefonttheme[onlymath]{serif}
  % \setbeamertemplate{navigation symbols}{}
  % \setbeamercovered{transparent}

  \setbeamercolor{title}{fg=white}
  \setbeamerfont{title}{series=\bfseries}
  \setbeamercolor{frametitle}{fg=black}
  \setbeamerfont{frametitle}{series=\bfseries}

  \setbeamercolor{section in head/foot}{fg=white}
  \setbeamerfont{section in head/foot}{series=\bfseries}
  \setbeamercolor{subsection in head/foot}{fg=white}
  \setbeamerfont{subsection in head/foot}{series=\bfseries}
  \setbeamercolor{author in head/foot}{fg=white}
  \setbeamerfont{author in head/foot}{series=\bfseries}
  \setbeamercolor{title in head/foot}{fg=white}
  \setbeamerfont{title in head/foot}{series=\bfseries}

  \setbeamercolor{block title}{use=structure,fg=white,bg=title in head/foot.bg}
  \setbeamerfont{block title}{series=\bfseries}
  \setbeamercolor{block body}{use=structure,fg=black,bg=black!1!white}
}

% Support graying out frame elements
\newcommand{\FrameOpague}{\setbeamercovered{again covered={\opaqueness<1->{40}}}}
% Transition slide
\newcommand{\transitionFrame}[1]{%
{%
  \begin{frame}[plain,noframenumbering]{}{} % the plain option removes the sidebar and header from the title page
    \setbeamertemplate{final page}[text]{\Large \textbf{#1}}
    \usebeamertemplate{final page}
  \end{frame}}
}

% Imported via UltiSnips
\usepackage{graphicx} % Loading the package
\graphicspath{{img/}} % Setting the default folder containing the graphics

\usepackage[numbers]{natbib}
\usepackage{appendixnumberbeamer}

% Here's where the presentation starts, with the info for the title slide
\title[Principles Explainable ML]{Principles and Practice of Explainable Machine Learning}
\author[Belle \& Papantonis]{%
  {Vaishak Belle}\inst{1}\inst{2}
  \and
  {Ioannis Papantonis}\inst{1}
}

\institute[U.\ Edinburgh]{%
  \textsuperscript{1}\textbf{University of Edinburgh}
  \and
  \textsuperscript{2}\textbf{Alan Turing Institute}
}
\date{October~8, 2020}

% Imported via UltiSnips
\input{global_macros}
\input{macros}

% Enable (uncolored) cross-reference hyperlinks
% Should always be last package loaded.
% See: https://tex.stackexchange.com/questions/103123/links-do-not-lead-to-right-pages
\usepackage{hyperref}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\section{Case Study}
\begin{frame}{Let's Start with a Case Study\ldots}
  \noindent
  Before examining the problem from a technical perspective, let's think through a \textit{real-world} scenario
  \begin{itemize}
    \item Help us identify salient ideas
    \item Allow us to construct a working vocabulary
  \end{itemize}

  \vspace{18pt}
  \onslide<2->{
    \noindent
    \textbf{Note}: A case study appears at the end of paper, but I think the following will yield a more fruitful discussion.
  }
\end{frame}

\begin{frame}{Fair Criminal Sentencing}
  \begin{itemize}[<+->]
    \setlength{\itemsep}{22pt}
    \onslide<+->{\item I get this is a bit heavy topic\ldots}

    \onslide<+->{\item \textbf{Sentence}: Punishment (e.g.,~fine, probation, imprisonment, restituion) assigned in relation to a specific criminal act.}

    \onslide<+->{\item \green{\textbf{Accurate}}/appropriate sentencing is \textbf{critical} for a healthy justice system.}

    \onslide<+->{%
      \item \textbf{Key Attributes of an Appropriate Sentencing Apparatus}
      \begin{itemize}
        \setlength{\itemsep}{3pt}
        \item \textit{Consistent}: Similar crimes/circumstances should yield similar punishments.
        \item \textit{Understandable}: Clarity \textit{why} the selected sentence is appropriate
        \item \textit{Transparent}: Knowledge of \textit{how} the sentence was selected sentence
        \item \textit{Sufficient}: Ensures justice for the victims and keeps the public safe
      \end{itemize}
    }
  \end{itemize}
\end{frame}

\begin{frame}{Problem with Sentencing Today}
  \onslide<+->{\textbf{\blue{Major Problem}}: Human juries/judges badly affected by bias\ldots}

  \onslide<+->{%
    \begin{itemize}
      \setlength{\itemsep}{22pt}
      \item \textbf{Racial Bias}: An African-American defendant is 5.9x as likely to be imprisoned as a white defendant. Hispanics are 3.1x as likely.~\citep{SentencingProject}

      \item \textbf{Gender Bias}: Men receive 63\% longer sentences on average than women do. Women are twice as likely to avoid incarceration if convicted.~\citep{Starr:2014}

      \item \textbf{Wealth Effects}: Poor defendants more likely to plead guilty since they cannot afford bail and lack a safety net to afford remaining in prison until trial
    \end{itemize}
  }
\end{frame}

\subsection{AI \& the Justice System}
\begin{frame}{Here's an Idea\ldots}
  \onslide<+->{Take the \textit{humans} out of sentencing
    \begin{itemize}
      \item Make it entirely ``data driven''
    \end{itemize}
  }

  \vspace{22pt}
  \onslide<+->{%
    Use machine learning to estimate the \green{recidivism rate}. \textbf{Three types of recidivism}:
    \begin{itemize}
      \item \textit{Pretrial recidivism}
      \item \textit{General recidivism}
      \item \textit{Pretrial recidivism}
    \end{itemize}
  }

  \vspace{22pt}
  \onslide<+->{\blue{\textbf{COMPAS}}: \underline{C}orrectional \underline{O}ffender \underline{M}anagement \underline{P}rofiling for \underline{A}lternative \underline{S}anctions
    \begin{itemize}
      \item Released: 2009
      \item \green{\textbf{Proprietary}} (Developed by private company Northpointe)
    \end{itemize}
  }
\end{frame}

\begin{frame}{You May See Where This is Going\ldots}
  \begin{center}
    \onslide<2->{
      \includegraphics[scale=0.55]{propublica_compas_small.png}
    }
  \end{center}
\end{frame}

\begin{frame}{Some of the Highlights (or Lowlights)\ldots}
  \noindent
  \onslide<+->{\textbf{Source}:~\citet{Angwin:2016} (7~years after COMPAS' initial release)}

  \begin{itemize}[<+->]
    \setlength{\itemsep}{12pt}
    \item ``blacks are almost twice as likely as whites to be labeled a higher risk but not actually re-offend''

    \item ``makes the opposite mistake among whites: They are much more likely than blacks to be labeled lower-risk but go on to commit other crimes.''

    \item Only 20\% of people predicted to commit violent crimes actually went on to do so.

    \item ``More \green{accurate} than a human''~\citep{Dressel:2018}
      \begin{itemize}[<+->]
        \item Individual with \textit{No Expertise} in Criminal Justice: 63\% accuracy
        \item COMPAS: 65\% accuracy
      \end{itemize}
  \end{itemize}

  \onslide<+->{
    \begin{block}{Takeaway}
      Explainable machine learning may have identified the model's implicit bias.
    \end{block}
  }
\end{frame}

\begin{frame}{Summary}
  \onslide<+->{
    \blue{\textbf{Key Themes of Practical Machine Learning}}:
      \begin{itemize}
        \setlength{\itemsep}{6pt}
        \item Proprietary IP vs.\ Transparency
        \item Model accuracy
        \item (Racial) bias
        \item Human understandability
        \item Importance of individual features (e.g.,~gender)
      \end{itemize}
  }

  \vspace{16pt}
  \onslide<+->{%
    \green{\textbf{Discussion Questions}}:
    \begin{itemize}
      \item What other high-level themes do you see in this example?
      \item Is there such a thing as a free lunch? Can I have it all?
    \end{itemize}
  }
\end{frame}

\section{Model Transparency}

\begin{frame}{Introduction}
  \begin{itemize}
    \setlength{\itemsep}{18pt}
    \item Machine learning systems are increasingly ubiquitous
    \item Understanding an ML system's decisions increases trust in those systems
    \item Many different stakeholders seek to understand different aspects of an ML model
      \begin{itemize}
        \item \textbf{Translation}: No one-size-fits-all explanation
      \end{itemize}
  \end{itemize}

  \onslide<2->{%
    \begin{block}{Purpose of this Paper}
      A broad survey of explainable ML to help \textit{industry practitioners} better understand the field and apply the right tools
    \end{block}
  }
\end{frame}

\section{Perspectives on Explainability}
\subsection{Model Transparency}

\begin{frame}{Properties of Transparent Models}{}
  \onslide<+->{
    \green{\textbf{Proprietary}} model COMPAS is maximally \textbf{\blue{opague}}, i.e., non-transparent
    \begin{itemize}
      \item Even can be considered a \green{black-box}
    \end{itemize}
  }

  \vspace{20pt}
  \onslide<+->{Levels of Model Transparency}
  \begin{itemize}[<+->]
    \setlength{\itemsep}{12pt}
    \item \green{\textbf{Simulatability}}: Ability of a human to manually simulate the model

    \item \green{\textbf{Decomposibility}}: Ability to break down a model into discrete (explainable) parts
      \begin{itemize}
        \item \textit{Example}: Input, parameters, computations, etc.
      \end{itemize}

    \item \green{\textbf{Algorithmic Transparency}}: Ability to understand the procedure the model uses to generate the output
      \begin{itemize}
        \item \textit{Example}: K-Nearest Neighbors
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Transparent to Opaque Models: A Fuzzy Continuum}{}
  The authors broadly categorize models as either:
   \begin{columns}
     \begin{column}{0.025\textwidth}
     \end{column}
     \begin{column}{0.40\textwidth}
       \begin{center}
         \textbf{\large \green{Transparent}}
         \begin{itemize}
           \item Linear/logistic regression
           \item Decision tree
           \item K-Nearest neighbors
           \item Rule-based learning
           \item Generalized additive models
           \item Bayesian networks
         \end{itemize}
       \end{center}
     \end{column}
     \begin{column}{0.05\textwidth}
     \end{column}
     \begin{column}{0.40\textwidth}
       \begin{center}
         \textbf{\large \green{Opaque}}
         \begin{itemize}
           \item Random forests
           \item Support vector machines
           \item Multi-layer (i.e.,~deep) neural networks
         \end{itemize}
       \end{center}
     \end{column}
     \begin{column}{0.025\textwidth}
     \end{column}
   \end{columns}

   \vspace{16pt}
   \onslide<2->{\blue{\textbf{Discussion}}: Going around around the room, each person will pick a particular model class and explain why a particular model falls into a particular category}
\end{frame}

\begin{frame}{Salient Theme on Algorithmic Transparency}
  \blue{\textbf{No Free Lunch}}*:  Clear, consistent trade-off between model complexity and transparency

  \vspace{16pt}
  \textbf{\blue{What that Means in Practice}}: Gaining transparency/explainability often means sacrificing (some) performance

  \vspace{16pt}
  \onslide<+->{\textbf{\green{Question}}: Are all models from a ``transparent'' model class actually transparent?}
  \begin{itemize}[<+->]
    \item No.  \textit{Why}?
    \item Similarly, not all models from an ``opaque'' model class is opaque.
    \item There's some nuance here.  It's a fuzzy classification.
  \end{itemize}

\end{frame}

\subsection{Evaluation Criteria}

\begin{frame}{Criteria for Evaluating an Explainability Method}
  \begin{itemize}[<+->]
    \setlength{\itemsep}{19pt}
    \item \green{\textbf{Comprehensibility}}: Are the extracted represents understandable to a human?
    \item \green{\textbf{Fidelity}}: How accurately do the extracted representations capture the opaque model?
    \item \green{\textbf{Accuracy}}: How well do the extracted representations predict unseen examples?
    \item \green{\textbf{Scalability}}: Ability of the method to scale to large input dimensions/model sizes
    \item \green{\textbf{Generality}}: Does the mechanism induce a special training procedure?
  \end{itemize}
\end{frame}

\subsection{Types of Explanations}
\begin{frame}{Types of Explanations}{}
  {\small
    \begin{itemize}[<+->]
      \setlength{\itemsep}{14pt}
      \item \textbf{\green{Text Explanation}}: Using symbols (e.g.,~natural language text, or propositional symbols) to explain the model's behavior
      \item \textbf{\green{Visual Explanation}}: Generate visualization that facilitate understanding, e.g.,~heat map
      \item \textbf{\green{Local Explanation}}: Explain how a model operates in a certain area of interest, e.g.,~explain the prediction for a specific instance
      \item \textbf{\green{Explanations by Example}}: Extract \textit{representative instances} from the training dataset
      \item \textbf{\green{Explanation by Simplification}}: Approximate an \textit{opaque} model using a simpler, easier-to-interpret one
      \item \textbf{\green{Feature Relevance Explanations}}: Quantify the influence of each feature
    \end{itemize}
  }
\end{frame}

\begin{frame}{Explanations by Example}{}
  \begin{columns}
    \begin{column}{0.45\textwidth}
      \begin{itemize}
        \setlength{\itemsep}{22pt}
        \item Common approach in human learning via \green{prototypical examples}
        \item \blue{\textbf{Example}}: \href{https://quickdraw.withgoogle.com/}{Google Quick, Draw!}~\citep{Cai:2019}
          \begin{itemize}
          \setlength{\itemsep}{8pt}
            \item Like charades or the old TV~show ``\href{https://en.wikipedia.org/wiki/Win,_Lose_or_Draw}{Win, Lose, or Draw}''
            \item Given a prompt and the user draws it
            \item AI tries to guess the picture
          \end{itemize}
      \end{itemize}
    \end{column}
    \begin{column}{0.1\textwidth}
    \end{column}
    \begin{column}{0.45\textwidth}
      \onslide<2->{%
        \includegraphics[scale=0.20]{avocado_quick_draw.png}
      }
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Local Explanation}
  \blue{\textbf{Obvious Question}}: Why was this \textit{particular instance} mispredicted?

  \vspace{16pt}
  \begin{center}
    \onslide<2->{
          \includegraphics[scale=0.264]{avocado_alternates_quick_draw.png}
    }
  \end{center}
\end{frame}

\begin{frame}[allowframebreaks]{Bibliography}{}
  {\tiny
    \frametitle{References}
    \bibliography{bib/ref.bib}
    \bibliographystyle{unsrtnat}
  }
\end{frame}
\end{document}
